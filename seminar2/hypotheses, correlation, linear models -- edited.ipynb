{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Случайные величины и гипотезы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "print(norm.rvs(loc=0, scale=1, size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples =  100000\n",
    "plt.figure(figsize = (14,6))\n",
    "for mean, std in [(0,1),(0,2),(2,1)]:\n",
    "    plt.hist(norm.rvs(loc=mean, scale=std, size=number_of_samples), bins=50, density=True)\n",
    "    plt.plot([mean] * 10, np.linspace(0, 0.5, 10), label='mean = ' + str(mean))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples =  100000\n",
    "# определите параметры распределения\n",
    "mean = #YOUR CODE HERE\n",
    "std = #YOUR CODE HERE\n",
    "\n",
    "# точка, которую будем проверять\n",
    "observed_value = #YOUR CODE HERE\n",
    "p_value = #YOUR CODE HERE\n",
    "significance = #YOUR CODE HERE\n",
    "if #YOUR CODE HERE\n",
    "    print('Reject hypothesis')\n",
    "else:\n",
    "    print('We cannot reject or accept hypothesis')\n",
    "\n",
    "\n",
    "sample = norm.rvs(loc=mean, scale=std, size=number_of_samples)\n",
    "\n",
    "density_domain = np.linspace(sample.min(), sample.max(), 100)\n",
    "density = norm.pdf(density_domain)\n",
    "\n",
    "plt.figure(figsize = (14, 6))\n",
    "plt.hist(sample, bins = 50, density=True, label='approximate distribution')\n",
    "plt.plot(observed_value, norm.pdf(observed_value), 'ro', label='observation')\n",
    "plt.plot(density_domain, density, label='real distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Корреляция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://idatassist.com/wp-content/uploads/2017/04/dreamstime_m_37904189-610x461.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Task:}$ Создайте 3 вектора. Первый и второй должны иметь корреляцию больше 0.5, первый и третий меньше -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_1 = #YOUR CODE HERE\n",
    "vector_2 = #YOUR CODE HERE\n",
    "vector_3 = #YOUR CODE HERE\n",
    "\n",
    "assert len(vector_1) == len(vector_2) == len(vector_3), \"Векторы разной длины\"\n",
    "\n",
    "v1_v2_corr = #YOUR CODE HERE\n",
    "v1_v3_corr = #YOUR CODE HERE\n",
    "\n",
    "assert v1_v2_corr > 0.5, \"Первый и второй векторы должны иметь корреляцию больше 0.5. У вас: \" + str(round(v1_v2_corr,2))\n",
    "assert v1_v3_corr < 0.5, \"Первый и третий векторы должны иметь корреляцию меньше -0.5. У вас: \" + str(round(v1_v3_corr,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation refers to $\\textbf{only linear}$ relationships between two variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 100, 0.1)\n",
    "y = np.sin(x)\n",
    "print(np.corrcoef(x,y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\alpha + \\beta_1x_1 + \\beta_2x_2+...+\\beta_nx_n + \\varepsilon$$\n",
    "\n",
    "$$MSE = \\sum (y_i -y)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сгенерированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from numpy.random import normal\n",
    "\n",
    "number_of_samples = 250\n",
    "\n",
    "X1 = normal(loc=0.0, scale=1, size=number_of_samples)\n",
    "X2 = normal(loc=0.0, scale=1, size=number_of_samples)\n",
    "\n",
    "noise = # YOUR CODE\n",
    "\n",
    "# задайте любое уравнение регрессии\n",
    "Y = # YOUR CODE\n",
    "\n",
    "## Adding noise for variables\n",
    "X1 += normal(loc=0.0, scale=0, size=number_of_samples)\n",
    "X2 += normal(loc=0.0, scale=0, size=number_of_samples)\n",
    "\n",
    "X = np.column_stack([X1, X2])\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), sharey=True)\n",
    "\n",
    "x_axis = np.arange(min(X1),max(X1), 0.1)\n",
    "step = max(X1) - min(X1)\n",
    "ax1.scatter(X1, Y, edgecolors=(0, 0, 0))\n",
    "ax1.plot(x_axis, results.params[0] + results.params[1] * x_axis, 'k--', lw=5, c='red')\n",
    "ax1.set_ylim(np.mean(Y) - step, np.mean(Y) + step)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('Y')\n",
    "\n",
    "x_axis = np.arange(min(X2), max(X2), 0.1)\n",
    "step = max(X2) - min(X2)\n",
    "ax2.scatter(X2, Y, edgecolors=(0, 0, 0))\n",
    "ax2.plot(x_axis, results.params[0] + results.params[2] * x_axis, 'k--', lw=5, c='red')\n",
    "ax2.set_ylim(np.mean(Y) - step, np.mean(Y) + step)\n",
    "ax2.set_xlabel('X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/t0zit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://vitalflux.com/wp-content/uploads/2015/02/fittings.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://theneural.files.wordpress.com/2011/07/valid2.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.random import normal\n",
    "np.random.seed(67)\n",
    "\n",
    "number_of_samples = 1000\n",
    "X1 = normal(loc=0.0, scale=1, size=number_of_samples)\n",
    "noise = normal(loc=0.0, scale=0.1, size=number_of_samples)\n",
    "Y = 1 + X1  + noise\n",
    "\n",
    "variables_list = [X1]\n",
    "for i in range(100):\n",
    "    variables_list.append(normal(loc=0.0, scale=0.1, size=number_of_samples))\n",
    "\n",
    "X = np.column_stack(variables_list)\n",
    "ntr = int(0.5 * X.shape[0])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X[:ntr,:], Y[:ntr])\n",
    "Y_predicted = model.predict(X)\n",
    "train_error = mean_squared_error(Y_predicted[:ntr], Y[:ntr])\n",
    "val_error = mean_squared_error(Y_predicted[ntr:], Y[ntr:])\n",
    "print('Training Error:  \\t',train_error)\n",
    "print('Validation Error:\\t',mean_squared_error(Y_predicted[ntr:], Y[ntr:]))\n",
    "print('diff:\\t\\t\\t', val_error - train_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus task\n",
    "\n",
    "Визуализируем эффект переобучения. Генерация данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1000\n",
    "X1 = normal(loc=0.0, scale=1, size=number_of_samples)\n",
    "noise = normal(loc=0.0, scale=1.2, size=number_of_samples)\n",
    "Y = 1 + X1 + noise\n",
    "plt.plot(X1, Y, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем приближать данные разными степенями полинома:\n",
    "$$\n",
    "  y(x) = a_0 + a_1x + \\ldots + a_nx^n\n",
    "$$\n",
    "\n",
    "Поэкспериментируйте с разными значениями степени и проанализируйте результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1000\n",
    "X1 = normal(loc=0.0, scale=1, size=number_of_samples)\n",
    "noise = normal(loc=0.0, scale=1.2, size=number_of_samples)\n",
    "Y = 1 + X1 + noise\n",
    "\n",
    "\n",
    "max_power = # YOUR CODE\n",
    "\n",
    "variables_list = []\n",
    "for i in range(max_power):\n",
    "    variables_list.append(X1 ** i)\n",
    "\n",
    "X = np.column_stack(variables_list)\n",
    "ntr = int(0.5 * X.shape[0])\n",
    "\n",
    "# определение линейной модели\n",
    "model = # YOUR CODE\n",
    "# обучение модели на обучающей (первые ntr строк) выборке\n",
    "# YOUR CODE\n",
    "\n",
    "# предсказание ответов для всей выборки\n",
    "Y_predicted = # YOUR CODE\n",
    "\n",
    "train_error = mean_squared_error(Y_predicted[:ntr], Y[:ntr])\n",
    "val_error = mean_squared_error(Y_predicted[ntr:], Y[ntr:])\n",
    "print('Training Error:  \\t',train_error)\n",
    "print('Validation Error:\\t',mean_squared_error(Y_predicted[ntr:], Y[ntr:]))\n",
    "print('diff:\\t\\t\\t', val_error - train_error)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.plot(X1, Y, 'o')\n",
    "ax1.set_ylim(Y.min(), Y.max())\n",
    "\n",
    "ax2.plot(X1[:ntr], Y[:ntr], 'o')\n",
    "ax2.plot(X1[ntr:], Y_predicted[ntr:], 'o')\n",
    "# comment it to see all dots\n",
    "ax2.set_ylim(Y.min(), Y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реальные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "data = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "data['PRICE'] = boston.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "Y = # YOUR CODE\n",
    "X = # YOUR CODE\n",
    "X = sm.add_constant(X)\n",
    "ols_model = sm.OLS(Y, X)\n",
    "ols_results = ols_model.fit()\n",
    "print(ols_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(breast_cancer.data[:,:28], columns = breast_cancer.feature_names[:28])\n",
    "data['CANCER'] = breast_cancer.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "Y = # YOUR CODE\n",
    "X = # YOUR CODE\n",
    "X = sm.add_constant(X)\n",
    "model = sm.Logit(Y, X)\n",
    "results = model.fit()\n",
    "print(results.summary2())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
